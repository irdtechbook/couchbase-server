
= クラスター

== フェイルオーバー

=== 分散アーキテクチャーのフェイルオーバー

Couchbase Serverにおけるフェイルオーバーの解説に進む前に、まず分散アーキテクチャー一般におけるフェイルオーバーについて、一般に妥当すると考えられる前提や要件などを整理します。

まず、広い意味でのフェールオーバーとして、以下の２種類があります。

==== 計画的なノードの削除（または、グレースフルフェイルオーバー）

クラスタから機能しているノードを削除するには、管理コンソール等を利用し、削除するノードを指定します。
その後クラスタをリバランスし、そのノードへのデータリクエストが他のノードで処理できるようにします。

削除対象ノードは、リバランスが完了するまでデータリクエストを処理することができます。完了時点で、他のノードでリクエストが処理されることになります。
すなわち、サービスが中断するようなことも、データを消失してしまうこともなく、ノードを削除してクラスタを（グレースフルに）リバランスできます。

機能しているノードを運用管理目的で削除したい場合、フェイルオーバではなく、ノード削除(Remove)の後、リバランスを実行します。

==== 障害時のノードの削除（または、ハードフェイルオーバー）

フェイルオーバーとは、そのノードをクラスタから削除し、他のノードにあるレプリケートしたデータを利用可能にすることです。

フェイルオーバーはノードの削除とは異なり、正常に動作していないノードに対して実行します。（機能しているノードをフェイルオーバした場合、フェイルオーバは即座にノードをクラスタから削除するため、データロスが発生する可能性があります。）

ノード障害時に他のノードへレプリケートされていないデータが存在していた場合データロスとなります（フェールオーバーしたノード上で、ディスクに永続化されていた場合、そのサーバーが復旧出来た場合には、データを復旧できる可能性があります（デルタリカバリー）。そうでない場合データは、完全に消失することになります。

以下、上記のハードフェイルオーバーに関する論点を整理していきます。

==== フェイルオーバー手段

ノード障害発生時には、フェイルオーバーを手動で実行するか、あるいは、自動的にフェイルオーバーをトリガーし、縮退モードでクラスタを稼働させるように設定することが考えられます。
フェイルオーバーはクラスタの性能を縮小させてしまうため、フェイルオーバーの状況をどのように処理すべきかをよく検討するべきです。

自動フェイルオーバーを利用すると、ユーザ操作なしにノードをフェイルオーバーできますが、ノード障害を発生させた問題の調査や特定は難しくなります。

手動フェイルオーバーによりクラスタを管理する場合、クラスタを監視し、問題の発生を検知できるようにします。
問題が発生したら、手動（あるいは外部スクリプト）でフェイルオーバーを実行します。
この手順では、より多くの監視や手動の操作が必要です。

==== 復旧

フェイルオーバー実行により、クラスタが縮退運転している間、クラスタ内に残る稼働中のノードに対する負荷は増大します。
クラスタがノード障害前と同じ状態で機能するためには、正常に機能するノードをクラスタに戻し、リバランスを実行して、ノード障害から復旧する必要があります。

手動でフェイルオーバーを実行しても、クラスタが自動的に実行するようにしても、障害の原因を解明する必要があります。
そして、正常に機能するノードをセットアップし、そのノードを追加し、クラスタをリバランスします。

フェイルオーバーシナリオに対処する際の、ノードの交換および追加に関する選択肢を以下に記します。

 * ハードウェアやシステム障害が起因してノードがダウンした場合、新規の交換用ノードをクラスタに追加してリバランスする。
 * クラスタのキャパシティ不足が原因でノードがダウンした場合、ノードの交換に加え、必要なキャパシティとするために必要な分だけノードを追加する。
 * ノードの障害が一時的なものである場合、そのノードをクラスタに再追加します。

==== 連鎖反応(Thundering Herd)

自動でコンポーネントを取り除くには、どんな分散システムでも問題が付き物です。
問題の原因を特定できない場合、または残りのシステムにかかる負荷を理解していない場合、自動フェイルオーバーは問題を解決するどころか、より多くの問題を発生させる可能性があります。
次のような状況では、問題を誘発する可能性があります。

クラスタが、キャパシティの80-90%で稼働しているとします。その時点で、順調に稼働していたとしても、クラスタのキャパシティは限界です。
ノード障害が発生し、ソフトウェアが自動的にノードをフェイルオーバーしたとします。
残りの4ノードでは負荷が増大し、正常に処理することはできないでしょう。
結果として負荷が増加することで、他のノードもダウンし、自動的にフェイルオーバーされてしまいます。
これらの障害は連鎖し、結果的にクラスタ全体の消失へとつながる可能性があります。

この場合の次善策は、単一ノード障害が発生してもクラスタの運用を続け、新しいサーバをクラスタに追加し、失われたキャパシティを補填して、ダウンしたノードを削除し、リバランスを実行することです。
こうすれば、クラスタ全体が利用不可となる代わりに、部分的な障害で済みます。単一ノード障害発生時には、一部のリクエストを処理できない方が、クラスタ全体の障害によってまったくリクエストを処理できないことよりも良いと言えます。

このような状況の予防策としては、ノード障害発生時にも十分な余剰のキャパシティを確保し、縮退運転ができるようにすることです。

==== 実行可能条件

ネットワークデバイスの故障が原因でネットワークが分割されてしまう、ネットワーク分断やスプリットブレインの状況を考慮し、多くのクラスターは以下の制約付きで自動フェイルオーバーを実装しています:

 * 自動フェイルオーバーは最低でも1クラスタに3台のノードを必要とする。これは、ネットワーク分断が発生した際に、2ノードのクラスタがお互いのノードをフェイルオーバーすることを防ぎます。クラスターによって、データのセットが構成されている場合、これはデータの整合性と一貫性を保護するために重要です。
 * 自動フェイルオーバーはレプリカデータによりサービスが継続可能な場合のみ実行される。
 * 自動フェイルオーバーは管理操作を必要とする前に一度だけ発動する。これは、フェイルオーバーの連鎖による、以後の性能や安定性の劣化を防ぐためです。多くの場合、クラスタが機能できなくなるまで劣化し続けるよりも、データセットの小さな部分にアクセスできなくなる方が望ましいでしょう。
 * 自動フェイルオーバーを実行するまでに一定の待機時間を設ける。これは一時的なネットワーク障害や、システムの遅延によって、誤ってノードがフェイルオーバーされることを防ぎます。

==== フェールオーバーの運用

手動フェイルオーバを行う場合、二つ方法があり、一つは人による監視、もう一つは外部システムを利用する方法です。

 * @<strong>{保守要員による運用} アラートに対して次の行動に関する意思決定をする人員を確保することは一つの選択肢です。
人間が広範囲のデータ、観測、経験を考慮し、最適な方法で状況を解決できるユニークな存在です。
多くの組織では、人が影響に対する考慮をしないままにフェイルオーバを自動化することを許可していません。
マニュアルによる介入を行うことの問題点はコンピュータベースのモニタリングシステムを利用することに比べ、対応が遅くなるということです。

 * @<strong>{外部モニタリング} もう一つの選択肢はREST APIを利用してクラスタをモニタリングするシステムを利用することです。
このような外部システムは、クラスタ以外のシステムコンポーネントに関しても考慮できるため、ノードのフェイルオーバにとって優位な位置に存在します。

例えば、モニタリングソフトウェアは、クラスタが依存するネットワークスイッチがダウンしていることを検知できます。
システムはノードをフェイルオーバしても状況は改善しないことが分かるため、ノードのフェイルオーバーはしません。

モニタリングシステムはクラスタ周辺のコンポーネントが機能しているか、クラスタ内の様々なノードが健全であるかを判断することもできます。
モニタリングシステムが、問題は単一のノードだけで起きており、クラスタ内の残りのノードで集約したトラフィックを処理できると判断すれば、システムからREST APIやコマンドラインツールを利用してそのノードをフェイルオーバーすることもできます。

=== Couchbase Serverフェイルオーバー機能

==== 自動フェイルオーバー仕様・制約

Couchbase Serverの自動フェイルオーバには多くの制約があります。
これは自動フェイルオーバーを利用する際に発生する可能性のある問題を回避するためです。

下記のようなケースでは、自動フェイルオーバーがトリガーされません。

 * @<strong>{イベント同時発生} 複数のイベントが同時に発生した場合、自動フェイルオーバーはトリガーされません。

 * @<strong>{フェイルオーバー連続実行} 管理者が指定したイベントの最大数までしか、自動フェイルオーバーはトリガーされません。許可される最大の最大値は3です。この自動フェイルオーバーの最大数に達すると、管理者がカウントを手動でリセットするまで、自動フェイルオーバーは発生しません。ただし、最大数に達する前にカウントを手動でリセットできます。
 * @<strong>{データ損失発生可能性} データ損失が発生する可能性のある状況では自動フェイルオーバーは発生しません。たとえば、バケットにレプリカがない場合はこのケースです。
 * @<strong>{非フェールオーバーノードの応答状況} （フェールオーバー対象となる）ノードが応答しなくなった後でも、ノードの過半数に接続できる場合のみ、自動フェールオーバーがトリガーされます（グループの場合、グループが応答しなくなった後でも、グループの過半数に連絡できる場合のみ）。

==== デフォルト設定

自動フェイルオーバはデフォルトでは無効となっています。
これは明示的に有効とされるまで、自動フェイルオーバーが発生することを防止するためです。

==== 待機時間

ノードがフェイルオーバされるまでに、最低でも30秒の遅延時間が必要です。
この時間を延ばすことはできますが、ソフトウェアはダウンしているかもしれないノードに対して複数回の死活監視を実行するようにハードコーディングされています。
これは機能しているが遅いノードのフェイルオーバや、ネットワーク接続問題によりフェイルオーバが発動することを防ぐためです。

==== 通知

REST APIを利用して、ノード障害が発生し、ノードが自動でフェイルオーバーされた際にCouchbase Serverがメールで通知を送信するように設定することができます。

=== サービス固有の自動フェイルオーバーポリシー

応答しないノード上の1つまたは複数のサービスのサービス固有の自動フェイルオーバーポリシーに準拠して自動フェイルオーバーがトリガーされます。

====[column] エディションによる差異
エンタープライズエディションでは、サービス毎にノードへ配置を構成するマルチディメンショナルスケーリング(MDS)が可能です。 MDSを利用している場合、ノードのフ ェイルオーバーの挙動は、そのノード上で稼働しているサービスが自動フェイルオーバーに対応しているかどうかにより決定されます。コミュニティエディションでは、全てのサービスが全てのノードで稼働することになるため、Dataサービスの仕様が満たされている必要があります。

====[/column]

==== Dataサービス

自動フェイルオーバーが有効化されるためには、最低、３ノードが必要です。

==== Indexサービス

自動フェイルオーバーはサポートされません。

==== その他のサービス

その他のサービス（Query、Service、Analytics、Eventing）のフェイルオーバーには最低、２ノードが必要です。

=== グループフェイルオーバー

ノードをラック（アベイラビリティゾーン）毎にグループ化することにより、グループフェイルオーバーの機能を活用することができます。
デフォルトでは無効とされています。
グループに多数のノードが含まれている場合でも、グループフェイルオーバーは単一のイベントと見なされます。

====[column] エディションによる差異
グループフェイルオーバーは、エンタープライズエディションでのみ使用できます。

====[/column]

=== ディスク障害に対するフェイルオーバー

クラスター単位で有効化することにより、ディスク障害に対するフェイルオーバーの機能を活用することができます。
デフォルトでは無効とされています。

====[column] エディションによる差異
ディスク障害に対するフェイルオーバーは、エンタープライズエディションでのみ使用できます。

====[/column]

=== フェイルオーバー実行方法

Couchbase Serverのフェイルオーバーは以下の方法で実行できます。

==== Webコンソール

 * WebコンソールのServersメニューに移動します。ノード一覧が表示され、クラスタがDownとして判定したノードのみFail Overボタンが有効になります。フェイルオーバーしたいノードのFail Overボタンをクリックします。
 * 確認・警告メッセージが表示されます。
 * FailOverをクリックし、ノードをフェイルオーバーします。Cancelを選択することもできます。

==== コマンドラインツール

@<tt>{couchbase-cli} の @<tt>{failover}コマンドを利用して、複数のノードをフェイルオーバできます。
ノードをフェイルオーバするには、フェイルオーバーするノードのIPアドレス（および標準ポート番号を利用していない場合でない場合はポート番号）を指定します。


//emlist{
couchbase-cli failover --cluster=<server(available)>:8091\
-u cluster-username -p cluster-password\
--server-failover=<server(target)>:8091
//}

成功すると、ノードがフェイルオーバされたことを示すメッセージが表示されます。

== コミュニケーション概要

Couchbase Serverにおけるネットワーク間通信の種類について整理します。

Couchbase Serverは、クライアントからクラスター、ノードからノード、およびクラスターからクラスターへの通信を処理します。また、サードパーティ製品への接続も提供します。

=== クライアントとクラスター間

クライアントアプリケーションは、サーバー定義の（複数の）アクセスポイントを介してCouchbase Serverクラスターと通信します。各アクセスポイントは、非暗号化の通信と暗号化通信の両方にポートを提供します。

=== ノード間

クラスターノードは、データの複製、インデックスの維持、ノードの状態の確認、クラスター構成への変更の伝達などのために相互通信します。

=== クラスター間

Couchbase Server-クラスターは、クロスデータセンターレプリケーションを使用して相互に通信します。

=== コネクター

Couchbase Serverクラスターはサードパーティ製品と通信します。コネクタ。Elasticsearch、Hadoop、Kafka、Spark、およびTalend用のコネクタが提供されています。ODBCおよびJDBC用のドライバーが提供されています。

== クライアント・クラスター間コミュニケーション

クライアントとクラスター間のコミュニケーションについて解説します。

=== クライアント接続における3つのフェーズ

クライアント接続は、認証と認可(承認)、検出(Discovery)、およびサービス接続の3つのフェーズで確立されます。

==== 認証と認可

クライアントは、ユーザー名とパスワードで認証されます。認証を介して、ユーザーはロールを取得します。ロールに含まれる権限によって、Couchbase Serverのリソースに対する操作が認可されます。

==== 検出(Discovery)

クラスターマップがクライアントに返されます。これは、現在のクラスタートポロジを示しています。クラスターマップは、クラスターを構成するノードのリスト、ノード間のサービス配置、およびノード間のデータ配置に関する情報を含みます。

クライアントは、これらの情報を持っているため、適切なノードへアクセスすることができます。これは、単に適切なサービスを提供するノードへアクセスできることを意味しているだけなく、データの作成や（検索クエリではなく、キー/IDによる）取得の際に、そのデータの管理を担当するノードへ直接アクセスができることを意味しています。

ここまでの処理は、ブートストラップと呼ばれます。

==== サービスへの接続

クラスターマップを取得すると、クライアントはサービスレベルの操作を実行するために必要な接続を確立します。

この時実行しようとする操作の種類・内容によって、認可が必要になる場合があります。クライアントが要求しているリソースへのアクセスに対する適切な権限に関連付けられているロールを、ユーザーが持っている場合、アクセスが許可されます。

クラスタートポロジが変更された場合、サービスへの接続要求の際に例外が発生する可能性があります。この場合、検出を再実行し、新しい接続で操作を再試行する必要があります。

=== 他の分散アーキテクチャーとの違い

上記の中でも、特に「検出」のプロセスの部分は、他の分散アーキテクチャーを持つデータプラットフォームと比べて、Couchbase Serverに独自な部分だといえます。

Couchbase Serverとは異なり、多くの分散アーキテクチャーを持つデータベースでは、クライアントとのコミュニケーションを担当する特別なノードが存在しています。この違いは、（メモリファーストアーキテクチャに加えて）Couchbase Serverが、低遅延・ハイスループットを実現する要素となっています。

